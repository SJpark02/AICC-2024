# Speech-Recognition Papers

담당자: 기흥 김
진행 상태: 진행 중
유형: 논문
미디어: https://images.unsplash.com/photo-1631903562086-bedfb534ef86?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1760&q=80
마감일: 2022년 8월 11일
게시일: 2022년 8월 12일

# IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)

## ㅇSPEECH-TRANSFORMER: A NO-RECURRENCE SEQUENCE-TO-SEQUENCE MODEL FOR SPEECH RECOGNITION

- 2018년도 논문
- transformer model 사용

[](https://sci-hub.se/downloads/2020-09-03/63/dong2018.pdf)

## ㅇSTATE-OF-THE-ART SPEECH RECOGNITION WITH SEQUENCE-TO-SEQUENCE MODELS

- 23 Feb 2018
- Google 논문
- Recurrent Neural Network Transducer (RNNT) 사용

[](https://arxiv.org/pdf/1712.01769.pdf)

## STREAMING END-TO-END SPEECH RECOGNITION FOR MOBILE DEVICES

- 15 Nov 2018
- Google 논문, CTC, RNN 혼합 모델 사용

![Untitled](Speech-Recognition%20Papers%2011122b78055a490aaaea1431bd94771d/Untitled.png)

![Untitled](Speech-Recognition%20Papers%2011122b78055a490aaaea1431bd94771d/Untitled%201.png)

[](https://arxiv.org/pdf/1811.06621.pdf)

## ㅇTRANSFORMER TRANSDUCER: A STREAMABLE SPEECH RECOGNITION MODEL
WITH TRANSFORMER ENCODERS AND RNN-T LOSS

- 14 Feb 2020
- Google 논문,
- RNN/Transformer 혼합 모델

[](https://arxiv.org/pdf/2002.02562.pdf)

## ㅇATTENTION IS ALL YOU NEED IN SPEECH SEPARATION

- 8 Mar 2021
- Speech Separation 모델 고안
- 이름은 SepFormer
- WSJ0-2/3mix datasets에 대하여 STOA 성능 달성

[](https://arxiv.org/pdf/2010.13154.pdf)

## ㅇQUARTZNET: DEEP AUTOMATIC SPEECH RECOGNITION WITH 1D TIME-CHANNEL SEPARABLE CONVOLUTIONS

- 22 Oct 2019
- NVIDIA paper
- 어찌저찌해서 WER 낮게 달성했음

![Untitled](Speech-Recognition%20Papers%2011122b78055a490aaaea1431bd94771d/Untitled%202.png)

[](https://arxiv.org/pdf/1910.10261.pdf)

## ㅇSELF-TRAINING FOR END-TO-END SPEECH RECOGNITION

- 23 Feb 2020
- Facebook AI Research
- It Used Self-traning, ensamble model

[](https://arxiv.org/pdf/1909.09116v2.pdf)

## ㅇ STREAMING AUTOMATIC SPEECH RECOGNITION WITH THE TRANSFORMER MODEL

- 30 Jun 2020
- Mitsubishi Electric Research Laboratories (MERL), **Cambridge**, MA, USA
- LibriSpeech에 대하여
2.8% and 7.2% WER for the “clean” and “other” test data

[](https://arxiv.org/pdf/2001.02674.pdf)

## ㅇSelf-training and Pre-training are Complementary for Speech Recognition

- 22 Oct 2020
- Facebook AI Research
- Librispeech achieves WERs of 1.5%/3.1%. 23 Feb 2020때보다 더 좋아짐.

[](https://arxiv.org/pdf/2010.11430.pdf)

## ㅇDEVELOPING REAL-TIME STREAMING TRANSFORMER TRANSDUCER FOR SPEECH RECOGNITION ON LARGE-SCALE DATASET

- 22 Oct 2020
- Microsoft Speech and Language Group, Microsoft Research Asia

[](https://arxiv.org/pdf/2010.11395.pdf)

## ㅇDEEP CONTEXTUALIZED ACOUSTIC REPRESENTATIONS FOR SEMI-SUPERVISED SPEECH RECOGNITION

- 9 Apr 2020
- Amazon AWS AI
- 42% and 19% relative improvement over the baseline on WSJ
eval92 and LibriSpeech test-clean, respectively

[](https://arxiv.org/pdf/1912.01679.pdf)

# **Conference of the International Speech Communication Association (INTERSPEECH)**

## ㅇUNSUPERVISED CROSS-LINGUAL REPRESENTATION LEARNING FOR SPEECH RECOGNITION

- 15 Dec 2020
- Facebook AI
- cross-lingual speech representations을 single model로 달성하는 논문임.
- 비슷한 모델에 비해 16% wer이 더 높다고 나옴.
- model name: XLSR

[](https://arxiv.org/pdf/2006.13979.pdf)